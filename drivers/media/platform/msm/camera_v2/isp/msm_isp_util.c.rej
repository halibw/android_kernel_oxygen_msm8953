--- drivers/media/platform/msm/camera_v2/isp/msm_isp_util.c
+++ drivers/media/platform/msm/camera_v2/isp/msm_isp_util.c
@@ -1,4 +1,4 @@
-/* Copyright (c) 2013-2018, The Linux Foundation. All rights reserved.
+/* Copyright (c) 2013-2017, The Linux Foundation. All rights reserved.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 and
@@ -20,8 +20,6 @@
 #include "msm_isp_stats_util.h"
 #include "msm_camera_io_util.h"
 #include "cam_smmu_api.h"
-#define CREATE_TRACE_POINTS
-#include "trace/events/msm_cam.h"
 
 #define MAX_ISP_V4l2_EVENTS 100
 #define MAX_ISP_REG_LIST 100
@@ -29,10 +27,6 @@ static DEFINE_MUTEX(bandwidth_mgr_mutex);
 static struct msm_isp_bandwidth_mgr isp_bandwidth_mgr;
 
 static uint64_t msm_isp_cpp_clk_rate;
-static struct dump_ping_pong_state dump_data;
-static struct dump_ping_pong_state tasklet_data;
-static DEFINE_SPINLOCK(dump_irq_lock);
-static DEFINE_SPINLOCK(dump_tasklet_lock);
 
 #define VFE40_8974V2_VERSION 0x1001001A
 
@@ -351,34 +345,6 @@ int msm_isp_unsubscribe_event(struct v4l2_subdev *sd, struct v4l2_fh *fh,
 	return msm_isp_process_event_subscription(fh, sub, false);
 }
 
-static int msm_isp_update_fe_frame_id(struct vfe_device *vfe_dev,
-	void *arg)
-{
-	struct msm_vfe_update_fe_frame_id *session_frameid = arg;
-	int rc = 0;
-	/*
-	* For Offline VFE, HAL expects same frame id
-	* for offline output which it requested in do_reprocess.
-	*/
-	vfe_dev->axi_data.src_info[VFE_PIX_0].frame_id =
-		   session_frameid->frame_id;
-	return rc;
-}
-
-static int msm_isp_restart_fe(struct vfe_device *vfe_dev,
-	void *arg)
-{
-	struct msm_vfe_restart_fe_cmd *rst_fe = arg;
-	int rc = 0;
-	/*
-	* In case of overflow recovery
-	* restart fetch engine
-	*/
-	if (rst_fe->restart_fe)
-		vfe_dev->fetch_engine_info.is_busy = 1;
-	return rc;
-}
-
 static int msm_isp_start_fetch_engine(struct vfe_device *vfe_dev,
 	void *arg)
 {
@@ -408,9 +374,13 @@ static int msm_isp_start_fetch_engine_multi_pass(struct vfe_device *vfe_dev,
 		fe_cfg->frame_id;
 
 	if (fe_cfg->offline_pass == OFFLINE_SECOND_PASS) {
-		stream_info = &vfe_dev->axi_data.stream_info[
-			HANDLE_TO_IDX(fe_cfg->output_stream_id)];
-		if (!stream_info) {
+		for (i = 0; i < VFE_AXI_SRC_MAX; i++) {
+			stream_info = &vfe_dev->axi_data.stream_info[i];
+			if (stream_info->stream_id == fe_cfg->output_stream_id)
+				break;
+		}
+
+		if (i == VFE_AXI_SRC_MAX) {
 			pr_err("%s: Couldn't find streamid 0x%X\n", __func__,
 				fe_cfg->output_stream_id);
 			return -EINVAL;
@@ -526,9 +496,6 @@ static int msm_isp_cfg_rdi(struct vfe_device *vfe_dev,
 		return -EINVAL;
 	}
 
-	vfe_dev->axi_data.
-		src_info[input_cfg->input_src].sof_counter_step = 1;
-
 	vfe_dev->axi_data.src_info[input_cfg->input_src].pixel_clock =
 		input_cfg->input_pix_clk;
 	vfe_dev->hw_info->vfe_ops.core_ops.cfg_rdi_reg(
@@ -598,10 +565,13 @@ static int msm_isp_set_dual_HW_master_slave_mode(
 	}
 
 	/* No lock needed here since ioctl lock protects 2 session from race */
-	/* Reset master SOF which refer slave in increment_frame_id function */
+	/* reset master SOF which refer slave in increment_frame_id function
+	 *
+	 */
 	vfe_dev->common_data->ms_resource.master_sof_info.frame_id = 0;
 	vfe_dev->common_data->ms_resource.master_sof_info.mono_timestamp_ms = 0;
-	/* Reset slave frame_id so that master will not jump */
+	/* we have only 1 slave so reset it frame_id so that master will
+	 * not jump*/
 	vfe_dev->common_data->ms_resource.slave_sof_info[0].frame_id = 0;
 	if (src_info != NULL &&
 		dual_hw_ms_cmd->dual_hw_ms_type == MS_TYPE_MASTER) {
@@ -958,19 +928,6 @@ static long msm_isp_ioctl_unlocked(struct v4l2_subdev *sd,
 		rc = msm_isp_start_fetch_engine_multi_pass(vfe_dev, arg);
 		mutex_unlock(&vfe_dev->core_mutex);
 		break;
-
-	case VIDIOC_MSM_ISP_RESTART_FE:
-		mutex_lock(&vfe_dev->core_mutex);
-		rc = msm_isp_restart_fe(vfe_dev, arg);
-		mutex_unlock(&vfe_dev->core_mutex);
-		break;
-
-	case VIDIOC_MSM_ISP_UPDATE_FE_FRAME_ID:
-		mutex_lock(&vfe_dev->core_mutex);
-		rc = msm_isp_update_fe_frame_id(vfe_dev, arg);
-		mutex_unlock(&vfe_dev->core_mutex);
-		break;
-
 	case VIDIOC_MSM_ISP_REG_UPDATE_CMD:
 		if (arg) {
 			enum msm_vfe_input_src frame_src =
@@ -1601,10 +1558,6 @@ int msm_isp_cal_word_per_line(uint32_t output_format,
 	case V4L2_PIX_FMT_P16GBRG10:
 	case V4L2_PIX_FMT_P16GRBG10:
 	case V4L2_PIX_FMT_P16RGGB10:
-	case V4L2_PIX_FMT_P16BGGR12:
-	case V4L2_PIX_FMT_P16GBRG12:
-	case V4L2_PIX_FMT_P16GRBG12:
-	case V4L2_PIX_FMT_P16RGGB12:
 		val = CAL_WORD(pixel_per_line, 1, 4);
 	break;
 	case V4L2_PIX_FMT_NV24:
@@ -1671,10 +1624,6 @@ enum msm_isp_pack_fmt msm_isp_get_pack_format(uint32_t output_format)
 	case V4L2_PIX_FMT_P16GBRG10:
 	case V4L2_PIX_FMT_P16GRBG10:
 	case V4L2_PIX_FMT_P16RGGB10:
-	case V4L2_PIX_FMT_P16BGGR12:
-	case V4L2_PIX_FMT_P16GBRG12:
-	case V4L2_PIX_FMT_P16GRBG12:
-	case V4L2_PIX_FMT_P16RGGB12:
 		return PLAIN16;
 	default:
 		msm_isp_print_fourcc_error(__func__, output_format);
@@ -1759,10 +1708,6 @@ int msm_isp_get_bit_per_pixel(uint32_t output_format)
 	case V4L2_PIX_FMT_QGRBG12:
 	case V4L2_PIX_FMT_QRGGB12:
 	case V4L2_PIX_FMT_Y12:
-	case V4L2_PIX_FMT_P16BGGR12:
-	case V4L2_PIX_FMT_P16GBRG12:
-	case V4L2_PIX_FMT_P16GRBG12:
-	case V4L2_PIX_FMT_P16RGGB12:
 		return 12;
 	case V4L2_PIX_FMT_SBGGR14:
 	case V4L2_PIX_FMT_SGBRG14:
@@ -1799,38 +1744,11 @@ void msm_isp_update_error_frame_count(struct vfe_device *vfe_dev)
 static int msm_isp_process_iommu_page_fault(struct vfe_device *vfe_dev)
 {
 	int rc = vfe_dev->buf_mgr->pagefault_debug_disable;
-	uint32_t irq_status0, irq_status1;
-	uint32_t overflow_mask;
-	unsigned long irq_flags;
 
-	/* Check if any overflow bit is set */
-	vfe_dev->hw_info->vfe_ops.core_ops.
-		get_overflow_mask(&overflow_mask);
-	vfe_dev->hw_info->vfe_ops.irq_ops.
-		read_irq_status(vfe_dev, &irq_status0, &irq_status1);
-	overflow_mask &= irq_status1;
-	spin_lock_irqsave(
-		&vfe_dev->common_data->common_dev_data_lock, irq_flags);
-	if (overflow_mask ||
-		atomic_read(&vfe_dev->error_info.overflow_state) !=
-			NO_OVERFLOW) {
-		spin_unlock_irqrestore(
-			&vfe_dev->common_data->common_dev_data_lock, irq_flags);
-		pr_err_ratelimited("%s: overflow detected during IOMMU\n",
-			__func__);
-		/* Don't treat the Overflow + Page fault scenario as fatal.
-		 * Instead try to do a recovery. Using an existing event as
-		 * as opposed to creating a new event.
-		 */
-		msm_isp_halt_send_error(vfe_dev, ISP_EVENT_PING_PONG_MISMATCH);
-	} else {
-		spin_unlock_irqrestore(
-			&vfe_dev->common_data->common_dev_data_lock, irq_flags);
-		pr_err("%s:%d] VFE%d Handle Page fault! vfe_dev %pK\n",
-			__func__, __LINE__,  vfe_dev->pdev->id, vfe_dev);
-		vfe_dev->hw_info->vfe_ops.axi_ops.halt(vfe_dev, 0);
-		msm_isp_halt_send_error(vfe_dev, ISP_EVENT_IOMMU_P_FAULT);
-	}
+	pr_err("%s:%d] VFE%d Handle Page fault! vfe_dev %pK\n", __func__,
+		__LINE__,  vfe_dev->pdev->id, vfe_dev);
+
+	msm_isp_halt_send_error(vfe_dev, ISP_EVENT_IOMMU_P_FAULT);
 
 	if (vfe_dev->buf_mgr->pagefault_debug_disable == 0) {
 		vfe_dev->buf_mgr->pagefault_debug_disable = 1;
@@ -1873,8 +1791,6 @@ void msm_isp_process_overflow_irq(
 	uint32_t force_overflow)
 {
 	uint32_t overflow_mask;
-	unsigned long flags;
-	struct msm_isp_event_data error_event;
 
 	/* if there are no active streams - do not start recovery */
 	if (!vfe_dev->axi_data.num_active_stream)
@@ -1898,86 +1814,71 @@ void msm_isp_process_overflow_irq(
 	if (!force_overflow)
 		overflow_mask &= *irq_status1;
 
-	if (!overflow_mask)
-		return;
-
-	spin_lock_irqsave(&vfe_dev->common_data->common_dev_data_lock,
-		flags);
-	if (atomic_cmpxchg(&vfe_dev->error_info.overflow_state,
-		NO_OVERFLOW, OVERFLOW_DETECTED)) {
-		spin_unlock_irqrestore(
-			&vfe_dev->common_data->common_dev_data_lock,
-			flags);
-		return;
-	}
-	if (vfe_dev->reset_pending == 1) {
-		pr_err("%s:%d failed: overflow %x during reset\n",
-			__func__, __LINE__, overflow_mask);
-		/* Clear overflow bits since reset is pending */
-		*irq_status1 &= ~overflow_mask;
-		spin_unlock_irqrestore(&vfe_dev->common_data->
-			common_dev_data_lock, flags);
-		return;
-	}
-	ISP_DBG("%s: VFE%d Bus overflow detected: start recovery!\n",
-		__func__, vfe_dev->pdev->id);
-
-	trace_msm_cam_isp_overflow(vfe_dev, *irq_status0, *irq_status1);
-
-	/* maks off irq for current vfe */
-	vfe_dev->recovery_irq0_mask = vfe_dev->irq0_mask;
-	vfe_dev->recovery_irq1_mask = vfe_dev->irq1_mask;
+	if (overflow_mask) {
+		struct msm_isp_event_data error_event;
 
-	vfe_dev->hw_info->vfe_ops.core_ops.
-		set_halt_restart_mask(vfe_dev);
-	vfe_dev->hw_info->vfe_ops.axi_ops.halt(vfe_dev, 0);
-	/* mask off other vfe if dual vfe is used */
-	if (vfe_dev->is_split) {
-		uint32_t other_vfe_id;
-		struct vfe_device *other_vfe_dev;
-
-		other_vfe_id = (vfe_dev->pdev->id == ISP_VFE0) ?
-			ISP_VFE1 : ISP_VFE0;
-		other_vfe_dev = vfe_dev->common_data->
-			dual_vfe_res->vfe_dev[other_vfe_id];
-		if (other_vfe_dev) {
-			other_vfe_dev->recovery_irq0_mask =
-				other_vfe_dev->irq0_mask;
-			other_vfe_dev->recovery_irq1_mask =
-				other_vfe_dev->irq1_mask;
+		if (vfe_dev->reset_pending == 1) {
+			pr_err("%s:%d failed: overflow %x during reset\n",
+				__func__, __LINE__, overflow_mask);
+			/* Clear overflow bits since reset is pending */
+			*irq_status1 &= ~overflow_mask;
+			return;
 		}
 
-		atomic_cmpxchg(&(vfe_dev->common_data->dual_vfe_res->
-			vfe_dev[other_vfe_id]->
-			error_info.overflow_state),
+		ISP_DBG("%s: VFE%d Bus overflow detected: start recovery!\n",
+			__func__, vfe_dev->pdev->id);
+
+		/* maks off irq for current vfe */
+		atomic_cmpxchg(&vfe_dev->error_info.overflow_state,
 			NO_OVERFLOW, OVERFLOW_DETECTED);
+		vfe_dev->recovery_irq0_mask = vfe_dev->irq0_mask;
+		vfe_dev->recovery_irq1_mask = vfe_dev->irq1_mask;
 
 		vfe_dev->hw_info->vfe_ops.core_ops.
-			set_halt_restart_mask(vfe_dev->common_data->
-			dual_vfe_res->vfe_dev[other_vfe_id]);
-		if (other_vfe_dev) {
-			other_vfe_dev->hw_info->vfe_ops.axi_ops.
-				halt(other_vfe_dev, 0);
+			set_halt_restart_mask(vfe_dev);
+
+		/* mask off other vfe if dual vfe is used */
+		if (vfe_dev->is_split) {
+			uint32_t other_vfe_id;
+			struct vfe_device *other_vfe_dev;
+
+			other_vfe_id = (vfe_dev->pdev->id == ISP_VFE0) ?
+				ISP_VFE1 : ISP_VFE0;
+			other_vfe_dev = vfe_dev->common_data->
+				dual_vfe_res->vfe_dev[other_vfe_id];
+			if (other_vfe_dev) {
+			  other_vfe_dev->recovery_irq0_mask =
+				  other_vfe_dev->irq0_mask;
+			  other_vfe_dev->recovery_irq1_mask =
+				  other_vfe_dev->irq1_mask;
+			}
+
+			atomic_cmpxchg(&(vfe_dev->common_data->dual_vfe_res->
+				vfe_dev[other_vfe_id]->
+				error_info.overflow_state),
+				NO_OVERFLOW, OVERFLOW_DETECTED);
+
+			vfe_dev->hw_info->vfe_ops.core_ops.
+				set_halt_restart_mask(vfe_dev->common_data->
+				dual_vfe_res->vfe_dev[other_vfe_id]);
 		}
-	}
 
-	/* reset irq status so skip further process */
-	*irq_status0 = 0;
-	*irq_status1 = 0;
+		/* reset irq status so skip further process */
+		*irq_status0 = 0;
+		*irq_status1 = 0;
 
-	/* send overflow event as needed */
-	if (atomic_read(&vfe_dev->error_info.overflow_state)
-		!= HALT_ENFORCED) {
-		memset(&error_event, 0, sizeof(error_event));
-		error_event.frame_id =
-			vfe_dev->axi_data.src_info[VFE_PIX_0].frame_id;
-		error_event.u.error_info.err_type =
-			ISP_ERROR_BUS_OVERFLOW;
-		msm_isp_send_event(vfe_dev,
-			ISP_EVENT_ERROR, &error_event);
+		/* send overflow event as needed */
+		if (atomic_read(&vfe_dev->error_info.overflow_state)
+			!= HALT_ENFORCED) {
+			memset(&error_event, 0, sizeof(error_event));
+			error_event.frame_id =
+				vfe_dev->axi_data.src_info[VFE_PIX_0].frame_id;
+			error_event.u.error_info.err_type =
+				ISP_ERROR_BUS_OVERFLOW;
+			msm_isp_send_event(vfe_dev,
+				ISP_EVENT_ERROR, &error_event);
+		}
 	}
-	spin_unlock_irqrestore(&vfe_dev->common_data->
-		common_dev_data_lock, flags);
 }
 
 void msm_isp_reset_burst_count_and_frame_drop(
@@ -2026,7 +1927,7 @@ irqreturn_t msm_isp_process_irq(int irq_num, void *data)
 	uint32_t error_mask0, error_mask1;
 
 	vfe_dev->hw_info->vfe_ops.irq_ops.
-		read_irq_status_and_clear(vfe_dev, &irq_status0, &irq_status1);
+		read_irq_status(vfe_dev, &irq_status0, &irq_status1);
 
 	if ((irq_status0 == 0) && (irq_status1 == 0)) {
 		ISP_DBG("%s:VFE%d irq_status0 & 1 are both 0\n",
@@ -2057,50 +1958,13 @@ irqreturn_t msm_isp_process_irq(int irq_num, void *data)
 		ISP_DBG("%s: error_mask0/1 & error_count are set!\n", __func__);
 		return IRQ_HANDLED;
 	}
-	dump_data.vfe_dev = (struct vfe_device *) data;
-	if (vfe_dev->is_split &&
-		(vfe_dev->common_data->dual_vfe_res->vfe_dev[
-			!vfe_dev->pdev->id]) &&
-		(vfe_dev->common_data->dual_vfe_res->vfe_dev[
-			!vfe_dev->pdev->id]->vfe_open_cnt)) {
-		spin_lock(&dump_irq_lock);
-		dump_data.arr[dump_data.first].current_vfe_irq.
-			vfe_id = vfe_dev->pdev->id;
-		dump_data.arr[dump_data.first].current_vfe_irq.
-			irq_status0 = irq_status0;
-		dump_data.arr[dump_data.first].current_vfe_irq.
-			irq_status1 = irq_status1;
-		dump_data.arr[dump_data.first].current_vfe_irq.
-			ping_pong_status = ping_pong_status;
-
-		dump_data.arr[dump_data.first].other_vfe.
-			vfe_id = (!vfe_dev->pdev->id);
-		vfe_dev->hw_info->vfe_ops.irq_ops.
-			read_irq_status(
-			vfe_dev->common_data->dual_vfe_res->vfe_dev[
-			!vfe_dev->pdev->id],
-			&dump_data.arr[dump_data.first].other_vfe.irq_status0,
-			&dump_data.arr[dump_data.first].other_vfe.irq_status1);
-			dump_data.arr[dump_data.first].other_vfe.
-		ping_pong_status =
-			vfe_dev->hw_info->vfe_ops.axi_ops.
-				get_pingpong_status(
-				vfe_dev->common_data->dual_vfe_res->vfe_dev[
-					!vfe_dev->pdev->id]);
-		msm_isp_get_timestamp(&dump_data.arr[dump_data.first].
-			other_vfe.ts, vfe_dev);
-		dump_data.first =
-			(dump_data.first + 1) % MAX_ISP_PING_PONG_DUMP_SIZE;
-		dump_data.fill_count++;
-		spin_unlock(&dump_irq_lock);
-	}
+
 	msm_isp_enqueue_tasklet_cmd(vfe_dev, irq_status0, irq_status1,
 					ping_pong_status);
 
 	return IRQ_HANDLED;
 }
 
-
 void msm_isp_do_tasklet(unsigned long data)
 {
 	unsigned long flags;
@@ -2136,24 +2000,6 @@ void msm_isp_do_tasklet(unsigned long data)
 		spin_unlock_irqrestore(&vfe_dev->tasklet_lock, flags);
 		ISP_DBG("%s: vfe_id %d status0: 0x%x status1: 0x%x\n",
 			__func__, vfe_dev->pdev->id, irq_status0, irq_status1);
-		if (vfe_dev->is_split) {
-			spin_lock(&dump_tasklet_lock);
-			tasklet_data.arr[tasklet_data.first].
-			current_vfe_irq.vfe_id = vfe_dev->pdev->id;
-			tasklet_data.arr[tasklet_data.first].
-			current_vfe_irq.core = smp_processor_id();
-			tasklet_data.arr[tasklet_data.first].
-			current_vfe_irq.irq_status0 = irq_status0;
-			tasklet_data.arr[tasklet_data.first].
-			current_vfe_irq.irq_status1 = irq_status1;
-			tasklet_data.arr[tasklet_data.first].
-			current_vfe_irq.ping_pong_status = pingpong_status;
-			tasklet_data.arr[tasklet_data.first].
-			current_vfe_irq.ts = ts;
-			tasklet_data.first =
-			(tasklet_data.first + 1) % MAX_ISP_PING_PONG_DUMP_SIZE;
-			spin_unlock(&dump_tasklet_lock);
-		}
 		irq_ops->process_reset_irq(vfe_dev,
 			irq_status0, irq_status1);
 		irq_ops->process_halt_irq(vfe_dev,
@@ -2212,8 +2058,6 @@ static void msm_vfe_iommu_fault_handler(struct iommu_domain *domain,
 		if (vfe_dev->vfe_open_cnt > 0) {
 			atomic_set(&vfe_dev->error_info.overflow_state,
 				HALT_ENFORCED);
-			pr_err_ratelimited("%s: fault address is %lx\n",
-				__func__, iova);
 			msm_isp_process_iommu_page_fault(vfe_dev);
 		} else {
 			pr_err("%s: no handling, vfe open cnt = %d\n",
@@ -2447,57 +2291,3 @@ void msm_isp_save_framedrop_values(struct vfe_device *vfe_dev,
 		spin_unlock_irqrestore(&stream_info->lock, flags);
 	}
 }
-
-void msm_isp_dump_irq_debug(void)
-{
-	uint32_t index, count, i;
-
-	if (dump_data.fill_count > MAX_ISP_PING_PONG_DUMP_SIZE) {
-		index = dump_data.first;
-		count = MAX_ISP_PING_PONG_DUMP_SIZE;
-	} else {
-		index = 0;
-		count = dump_data.first;
-	}
-	for (i = 0; i < count; i++) {
-		trace_msm_cam_ping_pong_debug_dump(dump_data.arr[index]);
-		index = (index + 1) % MAX_ISP_PING_PONG_DUMP_SIZE;
-	}
-}
-
-void msm_isp_dump_taskelet_debug(void)
-{
-	uint32_t index, count, i;
-
-	if (tasklet_data.fill_count > MAX_ISP_PING_PONG_DUMP_SIZE) {
-		index = tasklet_data.first;
-		count = MAX_ISP_PING_PONG_DUMP_SIZE;
-	} else {
-		index = 0;
-		count = tasklet_data.first;
-	}
-	for (i = 0; i < count; i++) {
-		trace_msm_cam_tasklet_debug_dump(tasklet_data.arr[index]);
-		index = (index + 1) % MAX_ISP_PING_PONG_DUMP_SIZE;
-	}
-}
-
-void msm_isp_dump_ping_pong_mismatch(void)
-{
-	int i;
-
-	spin_lock(&dump_tasklet_lock);
-	for (i = 0; i < MAX_VFE; i++) {
-		dump_data.vfe_dev->hw_info->vfe_ops.axi_ops.
-			clear_irq_mask(
-		dump_data.vfe_dev->common_data->dual_vfe_res->vfe_dev[i]);
-		synchronize_irq(
-		(uint32_t)dump_data.vfe_dev->common_data->dual_vfe_res->vfe_dev[
-			i]->vfe_irq->start);
-	}
-	trace_msm_cam_string(" ***** msm_isp_dump_irq_debug ****");
-	msm_isp_dump_irq_debug();
-	trace_msm_cam_string(" ***** msm_isp_dump_taskelet_debug ****");
-	msm_isp_dump_taskelet_debug();
-	spin_unlock(&dump_tasklet_lock);
-}
